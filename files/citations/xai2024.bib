@InProceedings{10.1007/978-3-031-63803-9_21,
author="Perera-Lago, Javier
and Toscano-Duran, Victor
and Paluzo-Hidalgo, Eduardo
and Narteni, Sara
and Rucco, Matteo",
editor="Longo, Luca
and Lapuschkin, Sebastian
and Seifert, Christin",
title="Application of the Representative Measure Approach to Assess the Reliability of Decision Trees in Dealing with Unseen Vehicle Collision Data",
booktitle="Explainable Artificial Intelligence",
year="2024",
publisher="Springer Nature Switzerland",
address="Cham",
pages="384--395",
abstract="Machine learning algorithms are fundamental components of novel data-informed Artificial Intelligence architecture. In this domain, the imperative role of representative datasets is a cornerstone in shaping the trajectory of artificial intelligence (AI) development. Representative datasets are needed to train machine learning components properly. Proper training has multiple impacts: it reduces the final model's complexity, power, and uncertainties. In this paper, we investigate the reliability of the {\$}{\$}{\backslash}varepsilon {\$}{\$}$\epsilon$-representativeness method to assess the dataset similarity from a theoretical perspective for decision trees. We decided to focus on the family of decision trees because it includes a wide variety of models known to be explainable. Thus, in this paper, we provide a result guaranteeing that if two datasets are related by {\$}{\$}{\backslash}varepsilon {\$}{\$}$\epsilon$-representativeness, i.e., both of them have points closer than {\$}{\$}{\backslash}varepsilon {\$}{\$}$\epsilon$, then the predictions by the classic decision tree are similar. Experimentally, we have also tested that {\$}{\$}{\backslash}varepsilon {\$}{\$}$\epsilon$-representativeness presents a significant correlation with the ordering of the feature importance. Moreover, we extend the results experimentally in the context of unseen vehicle collision data for XGboost, a machine-learning component widely adopted for dealing with tabular data.",
isbn="978-3-031-63803-9"
}

